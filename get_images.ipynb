{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"F:\\\\Axis dataset\\\\Dataset\\\\real/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pylab import *\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from sklearn.svm import LinearSVC\n",
    "from PIL import Image\n",
    "from sklearn import svm\n",
    "from scipy.cluster.vq import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import tree\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import imagehash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genuine_image_paths = \"F:\\\\Axis dataset\\\\Dataset\\\\real/\"\n",
    "forged_image_paths = \"F:\\\\Axis dataset\\\\Dataset\\\\forged/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genuine_image_features = [[] for x in range(12)]\n",
    "forged_image_features = [[] for x in range(12)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genuine_image_filenames = listdir(genuine_image_paths)\n",
    "forged_image_filenames = listdir(forged_image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for name in genuine_image_filenames:\n",
    "    signature_id = int(name.split('_')[0][-3:])\n",
    "    genuine_image_features[signature_id - 1].append({\"name\": name})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for name in forged_image_filenames:\n",
    "    signature_id = int(name.split('_')[0][-3:])\n",
    "    forged_image_features[signature_id - 1].append({\"name\": name})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_image(path, display=False):\n",
    "    raw_image = cv2.imread(path)\n",
    "    bw_image = cv2.cvtColor(raw_image, cv2.COLOR_BGR2GRAY)\n",
    "    bw_image = 255 - bw_image\n",
    "\n",
    "    if display:\n",
    "        cv2.imshow(\"RGB to Gray\", bw_image)\n",
    "        cv2.waitKey()\n",
    "\n",
    "    _, threshold_image = cv2.threshold(bw_image, 30, 255, 0)\n",
    "\n",
    "    if display:\n",
    "        cv2.imshow(\"Threshold\", threshold_image)\n",
    "        cv2.waitKey()\n",
    "\n",
    "    return threshold_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_contour_features(im, display=False):\n",
    "    '''\n",
    "    :param im: input preprocessed image\n",
    "    :param display: flag - if true display images\n",
    "    :return:aspect ratio of bounding rectangle, area of : bounding rectangle, contours and convex hull\n",
    "    '''\n",
    "\n",
    "    rect = cv2.minAreaRect(cv2.findNonZero(im))\n",
    "    box = cv2.boxPoints(rect)\n",
    "    box = np.int0(box)\n",
    "\n",
    "    w = np.linalg.norm(box[0] - box[1])\n",
    "    h = np.linalg.norm(box[1] - box[2])\n",
    "\n",
    "    aspect_ratio = max(w, h) / min(w, h)\n",
    "    bounding_rect_area = w * h\n",
    "\n",
    "    if display:\n",
    "        image1 = cv2.drawContours(im.copy(), [box], 0, (120, 120, 120), 2)\n",
    "        cv2.imshow(\"a\", cv2.resize(image1, (0, 0), fx=2.5, fy=2.5))\n",
    "        cv2.waitKey()\n",
    "\n",
    "    hull = cv2.convexHull(cv2.findNonZero(im))\n",
    "\n",
    "    if display:\n",
    "        convex_hull_image = cv2.drawContours(im.copy(), [hull], 0, (120, 120, 120), 2)\n",
    "        cv2.imshow(\"a\", cv2.resize(convex_hull_image, (0, 0), fx=2.5, fy=2.5))\n",
    "        cv2.waitKey()\n",
    "\n",
    "    im2, contours, hierarchy = cv2.findContours(im.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if display:\n",
    "        contour_image = cv2.drawContours(im.copy(), contours, -1, (120, 120, 120), 3)\n",
    "        cv2.imshow(\"a\", cv2.resize(contour_image, (0, 0), fx=2.5, fy=2.5))\n",
    "        cv2.waitKey()\n",
    "\n",
    "    contour_area = 0\n",
    "    for cnt in contours:\n",
    "        contour_area += cv2.contourArea(cnt)\n",
    "    hull_area = cv2.contourArea(hull)\n",
    "\n",
    "    return aspect_ratio, bounding_rect_area, hull_area, contour_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "des_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sift(im, path, display=False):\n",
    "    raw_image = cv2.imread(path)\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    kp, des = sift.detectAndCompute(im, None)\n",
    "\n",
    "    if display:\n",
    "        cv2.drawKeypoints(im, kp, raw_image)\n",
    "        cv2.imshow('sift_keypoints.jpg', cv2.resize(raw_image, (0, 0), fx=3, fy=3))\n",
    "        cv2.waitKey()\n",
    "\n",
    "    return (path, des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cor = 0\n",
    "wrong = 0\n",
    "\n",
    "im_contour_features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(12):\n",
    "    des_list = []\n",
    "    for im in genuine_image_features[i]:\n",
    "        image_path = genuine_image_paths + \"/\" + im['name']\n",
    "        preprocessed_image = preprocess_image(image_path)\n",
    "        hash = imagehash.phash(Image.open(image_path))\n",
    "\n",
    "        aspect_ratio, bounding_rect_area, convex_hull_area, contours_area = \\\n",
    "            get_contour_features(preprocessed_image.copy(), display=False)\n",
    "\n",
    "        hash = int(str(hash), 16)\n",
    "        im['hash'] = hash\n",
    "        im['aspect_ratio'] = aspect_ratio\n",
    "        im['hull_area/bounding_area'] = convex_hull_area / bounding_rect_area\n",
    "        im['contour_area/bounding_area'] = contours_area / bounding_rect_area\n",
    "\n",
    "        im_contour_features.append([hash, aspect_ratio, convex_hull_area / bounding_rect_area, contours_area / bounding_rect_area])\n",
    "\n",
    "        des_list.append(sift(preprocessed_image, image_path))\n",
    "        \n",
    "    for im in forged_image_features[i]:\n",
    "        image_path = forged_image_paths + \"/\" + im['name']\n",
    "        preprocessed_image = preprocess_image(image_path)\n",
    "        hash = imagehash.phash(Image.open(image_path))\n",
    "\n",
    "        aspect_ratio, bounding_rect_area, convex_hull_area, contours_area = \\\n",
    "            get_contour_features(preprocessed_image.copy(), display=False)\n",
    "\n",
    "        hash = int(str(hash), 16)\n",
    "        im['hash'] = hash\n",
    "        im['aspect_ratio'] = aspect_ratio\n",
    "        im['hull_area/bounding_area'] = convex_hull_area / bounding_rect_area\n",
    "        im['contour_area/bounding_area'] = contours_area / bounding_rect_area\n",
    "\n",
    "        im_contour_features.append([hash, aspect_ratio, convex_hull_area / bounding_rect_area, contours_area / bounding_rect_area])\n",
    "\n",
    "        des_list.append(sift(preprocessed_image, image_path))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors = des_list[0][1]\n",
    "for image_path, descriptor in des_list[1:]:\n",
    "    descriptors = np.vstack((descriptors, descriptor))\n",
    "k = 500\n",
    "voc, variance = kmeans(descriptors, k, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im_features = np.zeros((len(genuine_image_features[i]) + len(forged_image_features[i]), k+4), \"float32\")\n",
    "for i in range(len(genuine_image_features[i]) + len(forged_image_features[i])):\n",
    "    words, distance = vq(des_list[i][1], voc)\n",
    "    for w in words:\n",
    "        im_features[i][w] += 1\n",
    "\n",
    "    for j in range(4):\n",
    "        im_features[i][k+j] = im_contour_features[i][j]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stdSlr = StandardScaler().fit(im_features)\n",
    "im_features = stdSlr.transform(im_features)\n",
    "\n",
    "train_genuine_features, test_genuine_features = im_features[0:3], im_features[3:5]\n",
    "\n",
    "train_forged_features, test_forged_features = im_features[5:8], im_features[8:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LinearSVC()\n",
    "clf.fit(np.concatenate((train_forged_features,train_genuine_features)), np.array([1 for x in range(len(train_forged_features))] + [2 for x in range(len(train_genuine_features))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genuine_res = clf.predict(test_genuine_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for res in genuine_res:\n",
    "    if int(res) == 2:\n",
    "        cor += 1\n",
    "    else:\n",
    "        wrong += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forged_res = clf.predict(test_forged_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "for res in forged_res:\n",
    "    if int(res) == 1:\n",
    "        cor += 1\n",
    "    else:\n",
    "        wrong += 1\n",
    "\n",
    "print(float(cor)/(cor+wrong))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.cm as cm\n",
    "from scipy import ndimage\n",
    "from skimage.measure import regionprops\n",
    "from skimage import io\n",
    "from skimage.filters import threshold_otsu   # For finding the threshold for grayscale to binary conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rgbgrey(img):\n",
    "    # Converts rgb to grayscale\n",
    "    greyimg = np.zeros((img.shape[0], img.shape[1]))\n",
    "    for row in range(len(img)):\n",
    "        for col in range(len(img[row])):\n",
    "            greyimg[row][col] = np.average(img[row][col])\n",
    "    return greyimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def greybin(img):\n",
    "    # Converts grayscale to binary\n",
    "    blur_radius = 0.8\n",
    "    img = ndimage.gaussian_filter(img, blur_radius)  # to remove small components or noise\n",
    "#     img = ndimage.binary_erosion(img).astype(img.dtype)\n",
    "    thres = threshold_otsu(img)\n",
    "    binimg = img > thres\n",
    "    binimg = np.logical_not(binimg)\n",
    "    return binimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preproc(path, img=None, display=True):\n",
    "    if img is None:\n",
    "        img = mpimg.imread(path)\n",
    "    if display:\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "    grey = rgbgrey(img) #rgb to grey\n",
    "    if display:\n",
    "        plt.imshow(grey, cmap = matplotlib.cm.Greys_r)\n",
    "        plt.show()\n",
    "    binimg = greybin(grey) #grey to binary\n",
    "    if display:\n",
    "        plt.imshow(binimg, cmap = matplotlib.cm.Greys_r)\n",
    "        plt.show()\n",
    "    r, c = np.where(binimg==1)\n",
    "    # Now we will make a bounding box with the boundary as the position of pixels on extreme.\n",
    "    # Thus we will get a cropped image with only the signature part.\n",
    "    signimg = binimg[r.min(): r.max(), c.min(): c.max()]\n",
    "    if display:\n",
    "        plt.imshow(signimg, cmap = matplotlib.cm.Greys_r)\n",
    "        plt.show()\n",
    "    return signimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Ratio(img):\n",
    "    a = 0\n",
    "    for row in range(len(img)):\n",
    "        for col in range(len(img[0])):\n",
    "            if img[row][col]==True:\n",
    "                a = a+1\n",
    "    total = img.shape[0] * img.shape[1]\n",
    "    return a/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Centroid(img):\n",
    "    numOfWhites = 0\n",
    "    a = np.array([0,0])\n",
    "    for row in range(len(img)):\n",
    "        for col in range(len(img[0])):\n",
    "            if img[row][col]==True:\n",
    "                b = np.array([row,col])\n",
    "                a = np.add(a,b)\n",
    "                numOfWhites += 1\n",
    "    rowcols = np.array([img.shape[0], img.shape[1]])\n",
    "    centroid = a/numOfWhites\n",
    "    centroid = centroid/rowcols\n",
    "    return centroid[0], centroid[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def EccentricitySolidity(img):\n",
    "    r = regionprops(img.astype(\"int8\"))\n",
    "    return r[0].eccentricity, r[0].solidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SkewKurtosis(img):\n",
    "    h,w = img.shape\n",
    "    x = range(w)  # cols value\n",
    "    y = range(h)  # rows value\n",
    "    #calculate projections along the x and y axes\n",
    "    xp = np.sum(img,axis=0)\n",
    "    yp = np.sum(img,axis=1)\n",
    "    #centroid\n",
    "    cx = np.sum(x*xp)/np.sum(xp)\n",
    "    cy = np.sum(y*yp)/np.sum(yp)\n",
    "    #standard deviation\n",
    "    x2 = (x-cx)**2\n",
    "    y2 = (y-cy)**2\n",
    "    sx = np.sqrt(np.sum(x2*xp)/np.sum(img))\n",
    "    sy = np.sqrt(np.sum(y2*yp)/np.sum(img))\n",
    "    \n",
    "    #skewness\n",
    "    x3 = (x-cx)**3\n",
    "    y3 = (y-cy)**3\n",
    "    skewx = np.sum(xp*x3)/(np.sum(img) * sx**3)\n",
    "    skewy = np.sum(yp*y3)/(np.sum(img) * sy**3)\n",
    "\n",
    "    #Kurtosis\n",
    "    x4 = (x-cx)**4\n",
    "    y4 = (y-cy)**4\n",
    "    # 3 is subtracted to calculate relative to the normal distribution\n",
    "    kurtx = np.sum(xp*x4)/(np.sum(img) * sx**4) - 3\n",
    "    kurty = np.sum(yp*y4)/(np.sum(img) * sy**4) - 3\n",
    "\n",
    "    return (skewx , skewy), (kurtx, kurty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getFeatures(path, img=None, display=False):\n",
    "    if img is None:\n",
    "        img = mpimg.imread(path)\n",
    "    img = preproc(path, display=display)\n",
    "    ratio = Ratio(img)\n",
    "    centroid = Centroid(img)\n",
    "    eccentricity, solidity = EccentricitySolidity(img)\n",
    "    skewness, kurtosis = SkewKurtosis(img)\n",
    "    retVal = (ratio, centroid, eccentricity, solidity, skewness, kurtosis)\n",
    "    return retVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getCSVFeatures(path, img=None, display=False):\n",
    "    if img is None:\n",
    "        img = mpimg.imread(path)\n",
    "    temp = getFeatures(path, display=display)\n",
    "    features = (temp[0], temp[1][0], temp[1][1], temp[2], temp[3], temp[4][0], temp[4][1], temp[5][0], temp[5][1])\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeCSV():\n",
    "    if not(os.path.exists('F:\\\\Axis dataset\\\\Dataset\\\\Features')):\n",
    "        os.mkdir('F:\\\\Axis dataset\\\\Dataset\\\\Features')\n",
    "        print('New folder \"Features\" created')\n",
    "    if not(os.path.exists('F:\\\\Axis dataset\\\\Dataset\\\\Features/Training')):\n",
    "        os.mkdir('F:\\\\Axis dataset\\\\Dataset\\\\Features/Training')\n",
    "        print('New folder \"Features/Training\" created')\n",
    "    if not(os.path.exists('F:\\\\Axis dataset\\\\Dataset\\\\Features/Testing')):\n",
    "        os.mkdir('F:\\\\Axis dataset\\\\Dataset\\\\Features/Testing')\n",
    "        print('New folder \"Features/Testing\" created')\n",
    "    # genuine signatures path\n",
    "    gpath = genuine_image_paths\n",
    "    # forged signatures path\n",
    "    fpath = forged_image_paths\n",
    "    for person in range(1,13):\n",
    "        per = ('00'+str(person))[-3:]\n",
    "        print('Saving features for person id-',per)\n",
    "        \n",
    "        with open('F:\\\\Axis dataset\\\\Dataset\\\\Features\\\\Training/training_'+per+'.csv', 'w') as handle:\n",
    "            handle.write('ratio,cent_y,cent_x,eccentricity,solidity,skew_x,skew_y,kurt_x,kurt_y,output\\n')\n",
    "            # Training set\n",
    "            for i in range(0,3):\n",
    "                source = os.path.join(gpath, per+per+'_00'+str(i)+'.png')\n",
    "                features = getCSVFeatures(path=source)\n",
    "                handle.write(','.join(map(str, features))+',1\\n')\n",
    "            for i in range(0,3):\n",
    "                source = os.path.join(fpath, '021'+per+'_00'+str(i)+'.png')\n",
    "                features = getCSVFeatures(path=source)\n",
    "                handle.write(','.join(map(str, features))+',0\\n')\n",
    "        \n",
    "        with open('F:\\\\Axis dataset\\\\Dataset\\\\Features\\\\Testing/testing_'+per+'.csv', 'w') as handle:\n",
    "            handle.write('ratio,cent_y,cent_x,eccentricity,solidity,skew_x,skew_y,kurt_x,kurt_y,output\\n')\n",
    "            # Testing set\n",
    "            for i in range(3, 5):\n",
    "                source = os.path.join(gpath, per+per+'_00'+str(i)+'.png')\n",
    "                features = getCSVFeatures(path=source)\n",
    "                handle.write(','.join(map(str, features))+',1\\n')\n",
    "            for i in range(3,5):\n",
    "                source = os.path.join(fpath, '021'+per+'_00'+str(i)+'.png')\n",
    "                features = getCSVFeatures(path=source)\n",
    "                handle.write(','.join(map(str, features))+',0\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testing(path):\n",
    "    feature = getCSVFeatures(path)\n",
    "    if not(os.path.exists('F:\\\\Axis dataset\\\\Dataset/TestFeatures')):\n",
    "        os.mkdir('F:\\\\Axis dataset\\\\Dataset/TestFeatures')\n",
    "    with open('F:\\\\Axis dataset\\\\Dataset\\\\TestFeatures/testcsv.csv', 'w') as handle:\n",
    "        handle.write('ratio,cent_y,cent_x,eccentricity,solidity,skew_x,skew_y,kurt_x,kurt_y\\n')\n",
    "        handle.write(','.join(map(str, feature))+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter person's id : 001\n",
      "Enter path of signature image : 021001_000.png\n",
      "Forged Image\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_input = 9\n",
    "train_person_id = input(\"Enter person's id : \")\n",
    "test_image_path = input(\"Enter path of signature image : \")\n",
    "train_path = 'F:\\\\Axis dataset\\\\Dataset\\\\Features\\\\Training/training_'+train_person_id+'.csv'\n",
    "testing(test_image_path)\n",
    "test_path = 'F:\\\\Axis dataset\\\\Dataset\\\\TestFeatures/testcsv.csv'\n",
    "\n",
    "def readCSV(train_path, test_path, type2=False):\n",
    "    # Reading train data\n",
    "    df = pd.read_csv(train_path, usecols=range(n_input))\n",
    "    train_input = np.array(df.values)\n",
    "    train_input = train_input.astype(np.float32, copy=False)  # Converting input to float_32\n",
    "    df = pd.read_csv(train_path, usecols=(n_input,))\n",
    "    temp = [elem[0] for elem in df.values]\n",
    "    correct = np.array(temp)\n",
    "    corr_train = keras.utils.to_categorical(correct,2)      # Converting to one hot\n",
    "    # Reading test data\n",
    "    df = pd.read_csv(test_path, usecols=range(n_input))\n",
    "    test_input = np.array(df.values)\n",
    "    test_input = test_input.astype(np.float32, copy=False)\n",
    "    if not(type2):\n",
    "        df = pd.read_csv(test_path, usecols=(n_input,))\n",
    "        temp = [elem[0] for elem in df.values]\n",
    "        correct = np.array(temp)\n",
    "        corr_test = kearas.utils.to_categorical(correct,2)      # Converting to one hot\n",
    "    if not(type2):\n",
    "        return train_input, corr_train, test_input, corr_test\n",
    "    else:\n",
    "        return train_input, corr_train, test_input\n",
    "\n",
    "tf.reset_default_graph()\n",
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 1000\n",
    "display_step = 1\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 7 # 1st layer number of neurons\n",
    "# n_hidden_2 = 10 # 2nd layer number of neurons\n",
    "# n_hidden_3 = 30 # 3rd layer\n",
    "n_classes = 2 # no. of classes (genuine or forged)\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, n_input])\n",
    "Y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1], seed=1)),\n",
    "#     'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "#     'h3': tf.Variable(tf.random_normal([n_hidden_2, n_hidden_3])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_1, n_classes], seed=2))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1], seed=3)),\n",
    "#     'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "#     'b3': tf.Variable(tf.random_normal([n_hidden_3])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes], seed=4))\n",
    "}\n",
    "\n",
    "\n",
    "# Create model\n",
    "def multilayer_perceptron(x):\n",
    "    layer_1 = tf.tanh((tf.matmul(x, weights['h1']) + biases['b1']))\n",
    "#     layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "#     layer_3 = tf.add(tf.matmul(layer_2, weights['h3']), biases['b3'])\n",
    "    out_layer = tf.tanh(tf.matmul(layer_1, weights['out']) + biases['out'])\n",
    "    return out_layer\n",
    "\n",
    "# Construct model\n",
    "logits = multilayer_perceptron(X)\n",
    "\n",
    "# Define loss and optimizer\n",
    "\n",
    "loss_op = tf.reduce_mean(tf.squared_difference(logits, Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "# For accuracies\n",
    "pred = tf.nn.softmax(logits)  # Apply softmax to logits\n",
    "correct_prediction = tf.equal(tf.argmax(pred,1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "def evaluate(train_path, test_path, type2=False):   \n",
    "    if not(type2):\n",
    "        train_input, corr_train, test_input, corr_test = readCSV(train_path, test_path)\n",
    "    else:\n",
    "        train_input, corr_train, test_input = readCSV(train_path, test_path, type2)\n",
    "    ans = 'Random'\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        # Training cycle\n",
    "        for epoch in range(training_epochs):\n",
    "            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "            _, cost = sess.run([train_op, loss_op], feed_dict={X: train_input, Y: corr_train})\n",
    "            if cost<0.0001:\n",
    "                break\n",
    "#             # Display logs per epoch step\n",
    "#             if epoch % 999 == 0:\n",
    "#                 print(\"Epoch:\", '%04d' % (epoch+1), \"cost={:.9f}\".format(cost))\n",
    "#         print(\"Optimization Finished!\")\n",
    "        \n",
    "        # Finding accuracies\n",
    "        accuracy1 =  accuracy.eval({X: train_input, Y: corr_train})\n",
    "#         print(\"Accuracy for train:\", accuracy1)\n",
    "#         print(\"Accuracy for test:\", accuracy2)\n",
    "        if type2 is False:\n",
    "            accuracy2 =  accuracy.eval({X: test_input, Y: corr_test})\n",
    "            return accuracy1, accuracy2\n",
    "        else:\n",
    "            prediction = pred.eval({X: test_input})\n",
    "            if prediction[0][1]>prediction[0][0]:\n",
    "                print('Genuine Image')\n",
    "                return True\n",
    "            else:\n",
    "                print('Forged Image')\n",
    "                return False\n",
    "\n",
    "\n",
    "def trainAndTest(rate=0.001, epochs=1700, neurons=7, display=False):    \n",
    "    start = time()\n",
    "\n",
    "    # Parameters\n",
    "    global training_rate, training_epochs, n_hidden_1\n",
    "    learning_rate = rate\n",
    "    training_epochs = epochs\n",
    "\n",
    "    # Network Parameters\n",
    "    n_hidden_1 = neurons # 1st layer number of neurons\n",
    "    # n_hidden_2 = 7 # 2nd layer number of neurons\n",
    "    # n_hidden_3 = 30 # 3rd layer\n",
    "\n",
    "    train_avg, test_avg = 0, 0\n",
    "    n = 10\n",
    "    for i in range(1,n+1):\n",
    "        if display:\n",
    "            print(\"Running for Person id\",i)\n",
    "        temp = ('0'+str(i))[-2:]\n",
    "        train_score, test_score = evaluate(train_path.replace('01',temp), test_path.replace('01',temp))\n",
    "        train_avg += train_score\n",
    "        test_avg += test_score\n",
    "    if display:\n",
    "#         print(\"Number of neurons in Hidden layer-\", n_hidden_1)\n",
    "        print(\"Training average-\", train_avg/n)\n",
    "        print(\"Testing average-\", test_avg/n)\n",
    "        print(\"Time taken-\", time()-start)\n",
    "    return train_avg/n, test_avg/n, (time()-start)/n\n",
    "\n",
    "\n",
    "evaluate(train_path, test_path, type2=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving features for person id- 001\n",
      "Saving features for person id- 002\n",
      "Saving features for person id- 003\n",
      "Saving features for person id- 004\n",
      "Saving features for person id- 005\n",
      "Saving features for person id- 006\n",
      "Saving features for person id- 007\n",
      "Saving features for person id- 008\n",
      "Saving features for person id- 009\n",
      "Saving features for person id- 010\n",
      "Saving features for person id- 011\n",
      "Saving features for person id- 012\n"
     ]
    }
   ],
   "source": [
    "makeCSV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = mpimg.imread(\"F:/Axis dataset/Dataset/forged/021001_000.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.9490196 , 0.9882353 , 0.99215686],\n",
       "        [0.94509804, 0.9882353 , 0.99215686],\n",
       "        [0.9490196 , 0.9882353 , 0.99215686],\n",
       "        ...,\n",
       "        [0.9490196 , 0.9882353 , 0.99215686],\n",
       "        [0.94509804, 0.9843137 , 0.99215686],\n",
       "        [0.9411765 , 0.9882353 , 0.99215686]],\n",
       "\n",
       "       [[0.9490196 , 0.9882353 , 0.99215686],\n",
       "        [0.9490196 , 0.9882353 , 0.99215686],\n",
       "        [0.9490196 , 0.9882353 , 0.99215686],\n",
       "        ...,\n",
       "        [0.9372549 , 0.9843137 , 0.99215686],\n",
       "        [0.9372549 , 0.9843137 , 0.99215686],\n",
       "        [0.9411765 , 0.9882353 , 0.99215686]],\n",
       "\n",
       "       [[0.9490196 , 0.9882353 , 0.99215686],\n",
       "        [0.94509804, 0.9882353 , 0.99215686],\n",
       "        [0.94509804, 0.9882353 , 0.99215686],\n",
       "        ...,\n",
       "        [0.9411765 , 0.9843137 , 0.99215686],\n",
       "        [0.9411765 , 0.9882353 , 0.99215686],\n",
       "        [0.9411765 , 0.9843137 , 0.99215686]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.9529412 , 0.9882353 , 0.9882353 ],\n",
       "        [0.9490196 , 0.9882353 , 0.99215686],\n",
       "        [0.94509804, 0.9843137 , 0.99215686],\n",
       "        ...,\n",
       "        [0.9490196 , 0.9882353 , 0.99215686],\n",
       "        [0.94509804, 0.9882353 , 0.99215686],\n",
       "        [0.9411765 , 0.9843137 , 0.99215686]],\n",
       "\n",
       "       [[0.9529412 , 0.9882353 , 0.99215686],\n",
       "        [0.9529412 , 0.9882353 , 0.99215686],\n",
       "        [0.9490196 , 0.9882353 , 0.99215686],\n",
       "        ...,\n",
       "        [0.94509804, 0.9882353 , 0.99215686],\n",
       "        [0.9411765 , 0.9843137 , 0.99215686],\n",
       "        [0.9411765 , 0.9843137 , 0.99215686]],\n",
       "\n",
       "       [[0.9529412 , 0.9882353 , 0.99215686],\n",
       "        [0.95686275, 0.9882353 , 0.9882353 ],\n",
       "        [0.9529412 , 0.9882353 , 0.9882353 ],\n",
       "        ...,\n",
       "        [0.9411765 , 0.9843137 , 0.99215686],\n",
       "        [0.93333334, 0.98039216, 0.99607843],\n",
       "        [0.9372549 , 0.9843137 , 0.99215686]]], dtype=float32)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"pc_axis.csv\", usecols=(n_input,))\n",
    "temp = [elem[0] for elem in df.values]\n",
    "correct = np.array(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.48415272, 0.48579194, 0.48798485, 0.57063307, 0.6080977 ,\n",
       "       0.60231293])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-b3effbe34699>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcorr_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meye\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcorr_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "corr_train = np.eye(2,dtype=np.float16)[(0.5,0),(1,0)]\n",
    "corr_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping opencv as it is not installed.\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv3'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-157-be3430ff11d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv3\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'021001_000.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mgray\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msift\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxfeatures2d\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSIFT_create\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv3'"
     ]
    }
   ],
   "source": [
    "import cv3 as cv2\n",
    "import numpy as np\n",
    "img = cv2.imread('021001_000.png')\n",
    "gray= cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "kp = sift.detect(gray,None)\n",
    "img=cv2.drawKeypoints(gray,kp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip uninstall opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                            Version           \n",
      "---------------------------------- ------------------\n",
      "absl-py                            0.2.0             \n",
      "alabaster                          0.7.10            \n",
      "anaconda-client                    1.6.5             \n",
      "anaconda-navigator                 1.6.9             \n",
      "anaconda-project                   0.8.0             \n",
      "asn1crypto                         0.22.0            \n",
      "astor                              0.6.2             \n",
      "astroid                            1.5.3             \n",
      "astropy                            2.0.2             \n",
      "babel                              2.5.0             \n",
      "backports.shutil-get-terminal-size 1.0.0             \n",
      "beautifulsoup4                     4.6.0             \n",
      "bitarray                           0.8.1             \n",
      "bkcharts                           0.2               \n",
      "blaze                              0.11.3            \n",
      "bleach                             1.5.0             \n",
      "bokeh                              0.12.10           \n",
      "boto                               2.48.0            \n",
      "Bottleneck                         1.2.1             \n",
      "CacheControl                       0.12.3            \n",
      "certifi                            2017.7.27.1       \n",
      "cffi                               1.10.0            \n",
      "chardet                            3.0.4             \n",
      "ChatterBot                         0.8.7             \n",
      "chatterbot-corpus                  1.1.4             \n",
      "click                              6.7               \n",
      "cloudpickle                        0.4.0             \n",
      "clyent                             1.2.2             \n",
      "colorama                           0.3.9             \n",
      "comtypes                           1.1.2             \n",
      "conda                              4.3.30            \n",
      "conda-build                        3.0.27            \n",
      "conda-verify                       2.0.0             \n",
      "contextlib2                        0.5.5             \n",
      "cryptography                       2.0.3             \n",
      "cycler                             0.10.0            \n",
      "Cython                             0.26.1            \n",
      "cytoolz                            0.8.2             \n",
      "dask                               0.15.3            \n",
      "datashape                          0.5.4             \n",
      "decorator                          4.1.2             \n",
      "distlib                            0.2.5             \n",
      "distributed                        1.19.1            \n",
      "docutils                           0.14              \n",
      "entrypoints                        0.2.3             \n",
      "et-xmlfile                         1.0.1             \n",
      "fastcache                          1.0.2             \n",
      "filelock                           2.0.12            \n",
      "Flask                              0.12.2            \n",
      "Flask-Cors                         3.0.3             \n",
      "future                             0.16.0            \n",
      "gast                               0.2.0             \n",
      "gevent                             1.2.2             \n",
      "glob2                              0.5               \n",
      "greenlet                           0.4.12            \n",
      "grpcio                             1.11.0            \n",
      "h5py                               2.7.0             \n",
      "heapdict                           1.0.0             \n",
      "html5lib                           0.9999999         \n",
      "idna                               2.6               \n",
      "ImageHash                          4.0               \n",
      "imageio                            2.2.0             \n",
      "imagesize                          0.7.1             \n",
      "ipykernel                          4.6.1             \n",
      "ipython                            6.1.0             \n",
      "ipython-genutils                   0.2.0             \n",
      "ipywidgets                         7.0.0             \n",
      "isort                              4.2.15            \n",
      "itsdangerous                       0.24              \n",
      "jdcal                              1.3               \n",
      "jedi                               0.10.2            \n",
      "Jinja2                             2.9.6             \n",
      "jsonschema                         2.6.0             \n",
      "jupyter-client                     5.1.0             \n",
      "jupyter-console                    5.2.0             \n",
      "jupyter-core                       4.3.0             \n",
      "jupyterlab                         0.27.0            \n",
      "jupyterlab-launcher                0.4.0             \n",
      "Keras                              2.1.5             \n",
      "lazy-object-proxy                  1.3.1             \n",
      "llvmlite                           0.20.0            \n",
      "locket                             0.2.0             \n",
      "lockfile                           0.12.2            \n",
      "lxml                               4.1.0             \n",
      "Markdown                           2.6.11            \n",
      "MarkupSafe                         1.0               \n",
      "mathparse                          0.1.2             \n",
      "matplotlib                         2.1.0             \n",
      "mccabe                             0.6.1             \n",
      "menuinst                           1.4.10            \n",
      "mistune                            0.7.4             \n",
      "mpmath                             0.19              \n",
      "msgpack-python                     0.4.8             \n",
      "multipledispatch                   0.4.9             \n",
      "navigator-updater                  0.1.0             \n",
      "nbconvert                          5.3.1             \n",
      "nbformat                           4.4.0             \n",
      "networkx                           2.0               \n",
      "nltk                               3.2.4             \n",
      "nose                               1.3.7             \n",
      "notebook                           5.0.0             \n",
      "numba                              0.35.0+10.g143f70e\n",
      "numexpr                            2.6.2             \n",
      "numpy                              1.15.4            \n",
      "numpydoc                           0.7.0             \n",
      "oauthlib                           2.1.0             \n",
      "odo                                0.5.1             \n",
      "olefile                            0.44              \n",
      "opencv-contrib-python              3.3.0.10          \n",
      "opencv-python                      3.3.0.10          \n",
      "openpyxl                           2.4.8             \n",
      "packaging                          16.8              \n",
      "pandas                             0.20.3            \n",
      "pandocfilters                      1.4.2             \n",
      "partd                              0.3.8             \n",
      "path.py                            10.3.1            \n",
      "pathlib2                           2.3.0             \n",
      "patsy                              0.4.1             \n",
      "pep8                               1.7.0             \n",
      "pickleshare                        0.7.4             \n",
      "Pillow                             4.2.1             \n",
      "pip                                18.1              \n",
      "pkginfo                            1.4.1             \n",
      "ply                                3.10              \n",
      "progress                           1.3               \n",
      "prompt-toolkit                     1.0.15            \n",
      "protobuf                           3.5.2.post1       \n",
      "psutil                             5.4.0             \n",
      "py                                 1.4.34            \n",
      "PyAutoGUI                          0.9.36            \n",
      "pycodestyle                        2.3.1             \n",
      "pycosat                            0.6.2             \n",
      "pycparser                          2.18              \n",
      "pycrypto                           2.6.1             \n",
      "pycurl                             7.43.0            \n",
      "pydotplus                          2.0.2             \n",
      "pyflakes                           1.6.0             \n",
      "Pygments                           2.2.0             \n",
      "pylint                             1.7.4             \n",
      "pymongo                            3.7.1             \n",
      "PyMsgBox                           1.0.6             \n",
      "pyodbc                             4.0.17            \n",
      "pyOpenSSL                          17.2.0            \n",
      "pyparsing                          2.2.0             \n",
      "PyScreeze                          0.1.14            \n",
      "PySocks                            1.6.7             \n",
      "pytest                             3.2.1             \n",
      "python-dateutil                    2.6.1             \n",
      "python-twitter                     3.4.2             \n",
      "PyTweening                         1.0.3             \n",
      "pytz                               2017.2            \n",
      "PyWavelets                         0.5.2             \n",
      "pywin32                            221               \n",
      "PyYAML                             3.12              \n",
      "pyzmq                              16.0.2            \n",
      "QtAwesome                          0.4.4             \n",
      "qtconsole                          4.3.1             \n",
      "QtPy                               1.3.1             \n",
      "requests                           2.18.4            \n",
      "requests-oauthlib                  1.0.0             \n",
      "rope                               0.10.5            \n",
      "ruamel-yaml                        0.11.14           \n",
      "scikit-image                       0.13.0            \n",
      "scikit-learn                       0.19.1            \n",
      "scipy                              0.19.1            \n",
      "seaborn                            0.8               \n",
      "setuptools                         39.0.1            \n",
      "simplegeneric                      0.8.1             \n",
      "singledispatch                     3.4.0.3           \n",
      "six                                1.11.0            \n",
      "snowballstemmer                    1.2.1             \n",
      "sortedcollections                  0.5.3             \n",
      "sortedcontainers                   1.5.7             \n",
      "Sphinx                             1.6.3             \n",
      "sphinxcontrib-websupport           1.0.1             \n",
      "spyder                             3.2.4             \n",
      "SQLAlchemy                         1.2.12            \n",
      "statsmodels                        0.8.0             \n",
      "sympy                              1.1.1             \n",
      "tables                             3.4.2             \n",
      "tblib                              1.3.2             \n",
      "tensorboard                        1.7.0             \n",
      "tensorflow                         1.7.0             \n",
      "tensorflow-gpu                     1.7.0             \n",
      "termcolor                          1.1.0             \n",
      "testpath                           0.3.1             \n",
      "toolz                              0.8.2             \n",
      "tornado                            4.5.2             \n",
      "tqdm                               4.23.4            \n",
      "traitlets                          4.3.2             \n",
      "typing                             3.6.2             \n",
      "unicodecsv                         0.14.1            \n",
      "urllib3                            1.22              \n",
      "wcwidth                            0.1.7             \n",
      "webencodings                       0.5.1             \n",
      "Werkzeug                           0.14.1            \n",
      "wheel                              0.31.0            \n",
      "widgetsnbextension                 3.0.2             \n",
      "win-inet-pton                      1.0.1             \n",
      "win-unicode-console                0.5               \n",
      "wincertstore                       0.2               \n",
      "wrapt                              1.10.11           \n",
      "xlrd                               1.1.0             \n",
      "XlsxWriter                         1.0.2             \n",
      "xlwings                            0.11.4            \n",
      "xlwt                               1.3.0             \n",
      "zict                               0.1.3             \n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('021001_000.png',cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shift = cv2.xfeatures2d.SIFT_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
